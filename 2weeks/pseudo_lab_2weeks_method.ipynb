{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RunnablePassthrough를 사용하면 입력을 변경하지 않거나 추가 키를 추가하여 전달할 수 있습니다. 이는 일반적으로 맵의 새 키에 데이터를 할당하기 위해 RunnableParallel과 함께 사용됩니다.\n",
    "\n",
    "- 단독으로 호출되는 RunnablePassthrough()는 단순히 입력을 받아 통과시킵니다.\n",
    "\n",
    "- 할당과 함께 호출된 RunnablePassthrough(.assign(...))는 입력을 받은 후 할당 함수에 전달된 추가 인수를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['name'], template='{name} 이 사람은 누구야?')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{name} 이 사람은 누구야?\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_api_key = \"youar_api_key_here\"\n",
    "\n",
    "model = ChatOpenAI(model = 'gpt-3.5-turbo-0125',api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='팀 쿡(Tim Cook)은 애플(Apple)의 CEO이며, 스티브 잡스(Steve Jobs)의 후계자로서 애플을 이끌고 있는 중요한 인물입니다. 그는 애플에서 1998년부터 근무하며 주요한 역할을 맡아 왔고, 2011년부터 CEO로 임명되어 애플의 성공과 혁신을 이끌어 왔습니다. 현재 애플은 세계적으로 가장 큰 기술 기업 중 하나로 자리매김하고 있습니다.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\":\"tim cook\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected mapping type as input to PromptTemplate. Received <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb 셀 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chain\u001b[39m.\u001b[39;49minvoke(\u001b[39m\"\u001b[39;49m\u001b[39m오바마\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# 에러가나는데, dict 형태로 key 값인 \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:2218\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2217\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 2218\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   2219\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2220\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2221\u001b[0m             patch_config(\n\u001b[1;32m   2222\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2223\u001b[0m             ),\n\u001b[1;32m   2224\u001b[0m         )\n\u001b[1;32m   2225\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/prompts/base.py:113\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtags:\n\u001b[1;32m    112\u001b[0m     config[\u001b[39m\"\u001b[39m\u001b[39mtags\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtags)\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[1;32m    114\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format_prompt_with_error_handling,\n\u001b[1;32m    115\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    116\u001b[0m     config,\n\u001b[1;32m    117\u001b[0m     run_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    118\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:1405\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1402\u001b[0m     context\u001b[39m.\u001b[39mrun(var_child_runnable_config\u001b[39m.\u001b[39mset, child_config)\n\u001b[1;32m   1403\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1404\u001b[0m         Output,\n\u001b[0;32m-> 1405\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1406\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1407\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1408\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1409\u001b[0m             config,\n\u001b[1;32m   1410\u001b[0m             run_manager,\n\u001b[1;32m   1411\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1412\u001b[0m         ),\n\u001b[1;32m   1413\u001b[0m     )\n\u001b[1;32m   1414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1415\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/prompts/base.py:92\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_format_prompt_with_error_handling\u001b[39m(\u001b[39mself\u001b[39m, inner_input: Dict) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PromptValue:\n\u001b[1;32m     91\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(inner_input, \u001b[39mdict\u001b[39m):\n\u001b[0;32m---> 92\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected mapping type as input to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(inner_input)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[1;32m     96\u001b[0m     missing \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_variables)\u001b[39m.\u001b[39mdifference(inner_input)\n\u001b[1;32m     97\u001b[0m     \u001b[39mif\u001b[39;00m missing:\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected mapping type as input to PromptTemplate. Received <class 'str'>."
     ]
    }
   ],
   "source": [
    "chain.invoke(\"오바마\") # 에러가나는데, dict 형태로 key 값인 name : \"오바마\" 의 형태로 입력을 하지 않아서다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Kevin De Bruyne는 벨기에 출신의 축구 선수로 맨체스터 시티에서 뛰고 있는 중필더이다. 그는 뛰어난 패스와 슈팅 능력을 가지고 있으며, 맨체스터 시티와 벨기에 대표팀에서 중요한 역할을 하고 있는 선수이다. 현재 세계적으로도 최고의 중필더 중 한 명으로 꼽히고 있다.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_2 = {\"name\": RunnablePassthrough()} | prompt | model #name 이라는 key 값으로 RunnablePassthrough를 넣어준다. \n",
    "chain_2.invoke(\"kevin de bruyne\") #invoke 에서 따로 설정없이 스트링만 입력하면 결과를 출력시킬 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG에서의 예제\n",
    "Chain = {\"document\":retriver, \"question\": RunnablePassthrough()} | prompt | model\n",
    "prompt = \"{retriever}에서 {question}에 대한 답변을 찾아주세요.\"\n",
    "#이러한 형태로 RAG 파이프라인을 구축해서 리트리버와 모델을 연결해줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🦜examples 에서의 예제를 봐보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "runnable = RunnableParallel( #코드를 병렬로 처리할때 쓰는 런어블 패럴\n",
    "    passed=RunnablePassthrough(), # 1\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3), # 1, mult =3 #assign 을 통해 값을 넣어줄 수 있다.\n",
    "    modified=lambda x: x[\"num\"] + 1,# 2\n",
    ")\n",
    "\n",
    "runnable.invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    [\"harrison worked at kensho\"], embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "retrieval_chain.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunnableParallel\n",
    "RunnableParallel은 시퀀스에서 다음 런처블의 입력 형식과 일치하도록 한 런처블의 출력을 조작하는 데 유용할 수 있습니다.\n",
    "\n",
    "여기서 프롬프트에 대한 입력은 \"context\" 및 \"question\" 키가 있는 맵이 될 것으로 예상됩니다. 사용자 입력은 질문일 뿐입니다. 따라서 리트리버를 사용하여 컨텍스트를 가져오고 \"question\" 키 아래의 사용자 입력을 통과시켜야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반적으로 두개의 Chain 을 묶어서 map_Chain 의 형태로 많이들 쓴다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': AIMessage(content=\"Why did the bear break up with his girlfriend? \\n\\nBecause he couldn't bear the distance between them!\", response_metadata={'finish_reason': 'stop', 'logprobs': None}),\n",
       " 'poem': AIMessage(content='In the forest deep, the bear roams free,\\nA majestic creature, wild and full of mystery.', response_metadata={'finish_reason': 'stop', 'logprobs': None})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(api_key=openai_api_key)\n",
    "joke_chain = ChatPromptTemplate.from_template(\"tell me a joke about {topic}\") | model\n",
    "poem_chain = (\n",
    "    ChatPromptTemplate.from_template(\"write a 2-line poem about {topic}\") | model\n",
    ")\n",
    "\n",
    "map_chain = RunnableParallel(joke=joke_chain, poem=poem_chain)\n",
    "\n",
    "map_chain.invoke({\"topic\": \"bear\"}) #2개의 결과를 병렬로 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate.from_template(\"{name}은 어디의 CEO 인가요\")\n",
    "prompt2 = PromptTemplate.from_template(\"{name}은 어떤 업적이 있나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain_1 = {\"name\": RunnablePassthrough()} | prompt1 | model\n",
    "chain_2 = {\"name\": RunnablePassthrough()} | prompt2 | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = RunnableParallel(a=chain_1, b=chain_2) #Chain 을 여러개 만들어서 묶어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': AIMessage(content=\"'tim cook'은 미국의 CEO이며, 미국의 기술기업인 애플(Apple)의 CEO입니다.\", response_metadata={'finish_reason': 'stop', 'logprobs': None}),\n",
       " 'b': AIMessage(content='\"country\": \"tim cook\"은 잘못된 입력입니다. Tim Cook은 애플(Apple)의 CEO로 유명한 인물이며, 테크놀로지 산업에서의 업적으로는 아이폰, 아이패드, 맥북 등의 제품 개발과 혁신적인 기술 발전에 기여한 것으로 알려져 있습니다.', response_metadata={'finish_reason': 'stop', 'logprobs': None})}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_chain.invoke({\"country\":\"tim cook\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이프라인에서 임의의 함수를 사용할 수 있습니다.  \n",
    "- 이러한 함수에 대한 모든 입력은 단일 인수가 되어야 한다는 점에 유의하세요. 여러 인수를 받는 함수가 있는 경우 단일 입력을 받아 여러 인수로 압축을 푸는 래퍼를 작성해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "model = ChatOpenAI(api_key=openai_api_key)\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"sonny\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"sonny\"), \"text2\": itemgetter(\"kangin\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='6 + 66 = 72', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"sonny\": \"kangin\", \"kangin\": \"lee-kang-in\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Accepting a Runnable Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 가능한 람다는 선택적으로 콜백, 태그 및 기타 구성 정보를 중첩된 실행에 전달하는 데 사용할 수 있는 RunnableConfig를 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import json\n",
    "\n",
    "\n",
    "def parse_or_fix(text: str, config: RunnableConfig):\n",
    "    fixing_chain = (\n",
    "        ChatPromptTemplate.from_template(\n",
    "            \"Fix the following text:\\n\\n```text\\n{input}\\n```\\nError: {error}\"\n",
    "            \" Don't narrate, just respond with the fixed data.\"\n",
    "        )\n",
    "        | ChatOpenAI(api_key=openai_api_key)\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return json.loads(text)\n",
    "        except Exception as e:\n",
    "            text = fixing_chain.invoke({\"input\": text, \"error\": e}, config)\n",
    "    return \"Failed to parse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'soony': 'kangin'}\n",
      "Tokens Used: 67\n",
      "\tPrompt Tokens: 58\n",
      "\tCompletion Tokens: 9\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.000105\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    output = RunnableLambda(parse_or_fix).invoke(\n",
    "        \"{soony: kangin}\", {\"tags\": [\"my-tag\"], \"callbacks\": [cb]}\n",
    "    )\n",
    "    print(output)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @Chain Decorator \n",
    "\n",
    "데코레이터는 기존의 Class에 기능을 추가 시킬 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb 셀 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     chain2 \u001b[39m=\u001b[39m prompt2 \u001b[39m|\u001b[39m ChatOpenAI() \u001b[39m|\u001b[39m StrOutputParser()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m chain2\u001b[39m.\u001b[39minvoke({\u001b[39m\"\u001b[39m\u001b[39mjoke\u001b[39m\u001b[39m\"\u001b[39m: parsed_output1})\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m custom_chain\u001b[39m.\u001b[39;49minvoke(\u001b[39m\"\u001b[39;49m\u001b[39mbears\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:3669\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3667\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   3668\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 3669\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_with_config(\n\u001b[1;32m   3670\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invoke,\n\u001b[1;32m   3671\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   3672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_config(config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc),\n\u001b[1;32m   3673\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   3674\u001b[0m     )\n\u001b[1;32m   3675\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   3677\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3678\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse `ainvoke` instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3679\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:1405\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1402\u001b[0m     context\u001b[39m.\u001b[39mrun(var_child_runnable_config\u001b[39m.\u001b[39mset, child_config)\n\u001b[1;32m   1403\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1404\u001b[0m         Output,\n\u001b[0;32m-> 1405\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1406\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1407\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1408\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1409\u001b[0m             config,\n\u001b[1;32m   1410\u001b[0m             run_manager,\n\u001b[1;32m   1411\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1412\u001b[0m         ),\n\u001b[1;32m   1413\u001b[0m     )\n\u001b[1;32m   1414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1415\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:3543\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3541\u001b[0m                 output \u001b[39m=\u001b[39m chunk\n\u001b[1;32m   3542\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3543\u001b[0m     output \u001b[39m=\u001b[39m call_func_with_variable_args(\n\u001b[1;32m   3544\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39minput\u001b[39;49m, config, run_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   3545\u001b[0m     )\n\u001b[1;32m   3546\u001b[0m \u001b[39m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3547\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb 셀 29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m output1 \u001b[39m=\u001b[39m ChatOpenAI(api_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msk-POJqCq0nD2WqndNvQxmWT3BlbkFJ8OjWO2AiOiZKxnf2jY3u\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39minvoke(prompt_val1)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m parsed_output1 \u001b[39m=\u001b[39m StrOutputParser()\u001b[39m.\u001b[39minvoke(output1)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m chain2 \u001b[39m=\u001b[39m prompt2 \u001b[39m|\u001b[39m ChatOpenAI() \u001b[39m|\u001b[39m StrOutputParser()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/pseudo_lab_2weeks_method.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m chain2\u001b[39m.\u001b[39minvoke({\u001b[39m\"\u001b[39m\u001b[39mjoke\u001b[39m\u001b[39m\"\u001b[39m: parsed_output1})\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\"What is the subject of this joke: {joke}\")\n",
    "\n",
    "@chain\n",
    "def custom_chain(text):\n",
    "    prompt_val1 = prompt1.invoke({\"topic\": text})\n",
    "    output1 = ChatOpenAI().invoke(prompt_val1)\n",
    "    parsed_output1 = StrOutputParser().invoke(output1)\n",
    "    chain2 = prompt2 | ChatOpenAI() | StrOutputParser()\n",
    "    return chain2.invoke({\"joke\": parsed_output1})\n",
    "\n",
    "custom_chain.invoke(\"bears\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
