{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt + LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "api_key = 'your-api-key'\n",
    "prompt = ChatPromptTemplate.from_template(\"{country} 의 중요한 역사는 무엇이 있나요?\")\n",
    "model = ChatOpenAI(api_key=api_key)\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 중요한 역사로는 다음과 같은 사건이 있습니다:\\n\\n1. 임진왜란(1592년~1598년): 일본의 도요토미 히데요시가 한국을 침공하여 발생한 전쟁으로, 한국은 큰 피해를 입었지만, 결국에는 승리하여 귀화하였습니다.\\n\\n2. 대한제국 선포(1897년): 대한제국은 1897년에 선포되어 독립적인 국가로 승격되었습니다.\\n\\n3. 일제 강점기(1910년~1945년): 일본은 1910년에 한국을 식민지로 통치하였고, 35년에 걸쳐 강제로 한국을 통제하였습니다.\\n\\n4. 3.1 운동(1919년): 대한민국 광주에서 시작된 이 운동은 한국인들의 독립을 위한 항일 운동으로, 일본에 대한 항거와 한국의 독립을 요구하였습니다.\\n\\n5. 한국전쟁(1950년~1953년): 한국전쟁은 남북한 간의 분단 이후, 북한의 침공으로 인하여 발생한 전쟁으로, 많은 희생자를 낸 전쟁이었습니다.\\n\\n이러한 역사적 사건들은 한국의 역사와 문화에 큰 영향을 미쳤으며, 현재의 한국을 이해하는 데 중요한 역할을 하고 있습니다.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country\": \"한국\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국의 중요한 역사에는 다양한 사건과 인물들이 포함되지만, 일부 중요한 사건과 인물들은 다음과 같습니다:\n",
      "\n",
      "1. 미국의 독립운동과 미국 혁명: 1775년부터 1783년까지 진행된 미국의 독립전쟁으로 인해 미국은 영국으로부터 독립을 선언하고 미국 합중국으로 탄생하게 되었습니다.\n",
      "\n",
      "2. 에이브러햄 링컨: 미국의 16대 대통령으로서 미국 내전의 주요 인물 중 하나로 꼽히며, 노예 해방 선언과 미국 내전의 승리를 이끈 인물로서 중요한 역사적 위치를 차지하고 있습니다.\n",
      "\n",
      "3. 민권 운동: 20세기 중반 미국에서 벌어진 민권 운동은 인종 차별과 인종 분리 정책에 반발하여 미국의 인권과 민주주의를 증진시키는 데 큰 영향을 미쳤습니다.\n",
      "\n",
      "4. 세계 대전 및 냉전: 미국은 20세기에 두 차례의 세계 대전과 냉전 시기를 겪으며 국제 정치와 경제에 큰 영향을 미쳤습니다.\n",
      "\n",
      "5. 9/11 테러: 2001년 9월 11일 발생한 미국 뉴욕의 世界貿易中心을 테러 공격으로 파괴된 사건은 미국과 세계 역사에 큰 영향을 미쳤습니다.\n",
      "\n",
      "이 외에도 미국의 역사는 다양한 중요한 사건과 인물들이 있으며, 이를 통해 미국의 발전과 성장을 이해할 수 있습니다."
     ]
    }
   ],
   "source": [
    "for i in chain.stream({\"country\": \"미국\"}):\n",
    "    print(i.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model.bind(stop=[\"\\n\"]) # 를 기준으로 멈춰라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='프랑스의 중요한 역사 중 일부는 다음과 같습니다:', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country\": \"France\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "chain = {\"country\":RunnablePassthrough()} |prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'독일의 중요한 역사 중 일부는 다음과 같습니다:\\n\\n1. 로마 제국의 붕괴 이후 독일 지역에서 발생한 분열과 군주권 싸움\\n2. 찰스 대제의 찰스의 큰 재정렬로 인한 식민 지배의 실현\\n3. 19세기 말부터 20세기 초까지의 독일 통일 운동\\n4. 제1차 세계 대전에서의 패배와 베르사유 조약 체결\\n5. 나치 독일의 세계 대전 참전과 유대인 대학살\\n6. 제2차 세계 대전에서의 패배와 동독과 서독의 분리\\n7. 베를린의 성벽 붕괴로 독일 통일의 성공\\n8. 북악 주변의 베를린 러브호프와 독일의 재통일.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"독일\") #Runnablepassthrough에 의해 {\"country\":\"독일\"}로 변환됨 , StrOutputParser에 의해 문자열로 변환됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦜RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gpt-researcher 0.0.8 requires langchain==0.0.335, but you have langchain 0.1.13 which is incompatible.\n",
      "gpt-researcher 0.0.8 requires openai~=1.3.3, but you have openai 1.12.0 which is incompatible.\n",
      "gpt-researcher 0.0.8 requires tavily-python==0.2.8, but you have tavily-python 0.3.1 which is incompatible.\n",
      "langchain-experimental 0.0.43 requires langchain<0.1,>=0.0.342, but you have langchain 0.1.13 which is incompatible.\n",
      "tavily-python 0.3.1 requires tiktoken==0.5.2, but you have tiktoken 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "korea = \"\"\"\n",
    "대한민국 축구대표팀 선수단 명단\n",
    "---\n",
    "공격수 (FW)\n",
    "정우영 (JEONG Wooyeong): 1999.09.20, 180cm / 70kg, VfB 슈투트가르트\n",
    "조규성 (CHO Guesung): 1998.01.25, 189cm / 82kg, FC 미트윌란\n",
    "주민규 (JOO Minkyu): 1990.04.13, 183cm / 79kg, 울산현대\n",
    "---\n",
    "미드필더 (MF)\n",
    "백승호 (PAIK Seungho): 1997.03.17, 182cm / 72kg, 버밍엄 시티\n",
    "손흥민 (SON Heungmin): 1992.07.08, 183cm / 78kg, 토트넘\n",
    "송민규 (SONG Minkyu): 1999.09.12, 179cm / 72kg, 전북현대모터스\n",
    "이강인 (LEE Kangin): 2001.02.19, 174cm / 72kg, 파리 생제르맹\n",
    "이재성 (LEE Jaesung): 1992.08.10, 180cm / 70kg, FSV 마인츠05\n",
    "정호연 (JEONG Hoyeon): 2000.09.28, 179cm / 68kg, 광주FC\n",
    "홍현석 (HONG Hyunseok): 1999.06.16, 175cm / 66kg, KAA 헨트\n",
    "황인범 (HWANG Inbeom): 1996.09.20, 177cm / 70kg, FK 츠르베나 즈베즈다\n",
    "---\n",
    "수비수 (DF)\n",
    "권경원 (KWON Kyungwon): 1992.01.31, 188cm / 83kg, 수원FC\n",
    "김문환 (KIM Moonhwan): 1995.08.01, 173cm / 64kg, 알 두하일 SC\n",
    "김민재 (KIM Minjae): 1996.11.15, 190cm / 88kg, FC 바이에른 뮌헨\n",
    "김영권 (KIM Younggwon): 1990.02.27, 186cm / 83kg, 울산현대\n",
    "김진수 (KIM Jinsu): 1992.06.13, 177cm / 68kg, 전북현대모터스\n",
    "박진섭 (PARK Jinseop): 1995.10.23, 182cm / 75kg, 전북현대모터스\n",
    "설영우 (SEOL Youngwoo): 1998.12.05, 180cm / 72kg, 울산현대\n",
    "이명재 (LEE Myungjae): 1993.11.04, 182cm / 68kg, 울산현대\n",
    "조유민 (CHO Yumin): 1996.11.17, 182cm / 70kg, 샤르자 FC\n",
    "---\n",
    "골키퍼 (GK)\n",
    "송범근 (SONG Bumkeun): 1997.10.15, 194cm / 88kg, 쇼난 밸마레\n",
    "이창근 (LEE Changgeun): 1993.08.30, 186cm / 75kg, 대전하나시티즌\n",
    "조현우 (JO Hyeonwoo): 1991.09.25, 189cm / 75kg, 울산현대\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "embedding=OpenAIEmbeddings(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = LocalFileStore(\"./cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=OpenAIEmbeddings(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embedding, store, namespace=embedding.model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-embedding-ada-002a0146fd6-d992-5270-a7d0-4e0789f91cd1',\n",
       " 'text-embedding-ada-002218bc9da-cee2-586a-bc37-d41780259536',\n",
       " 'text-embedding-ada-002be8d00b4-6909-593c-a802-63ccb0a79efd',\n",
       " 'text-embedding-ada-00254317ce7-ea08-5df2-acc4-7ba7f72aeace',\n",
       " 'text-embedding-ada-00219bae6aa-dc2c-5fa3-9ca5-6905aabf4a78',\n",
       " 'text-embedding-ada-002b73d6f25-0773-5348-b0ed-9dcd53e10def',\n",
       " 'text-embedding-ada-0029a715424-06e5-58cb-ba63-60733eda344b',\n",
       " 'text-embedding-ada-00210a59bed-6d11-58ff-a06a-da9f5ea03a86',\n",
       " 'text-embedding-ada-0026c88acb2-9591-56f3-af7d-b467885e6a55',\n",
       " 'text-embedding-ada-002a6f393b1-3e09-5c26-b59d-714111fccebc',\n",
       " 'text-embedding-ada-00253133f22-d535-58ad-b3cb-464ef56df475',\n",
       " 'text-embedding-ada-0020d6e3ba2-323c-5da0-9404-73365db9ce19',\n",
       " 'text-embedding-ada-0020a95c2da-3730-55d1-ad8a-a8a71f1cc9ec',\n",
       " 'text-embedding-ada-002c9219b7d-53b8-540b-be4a-dd8d12c32d48',\n",
       " 'text-embedding-ada-0026926a656-ab19-5a8f-a415-37842d4e70c3',\n",
       " 'text-embedding-ada-0021c243508-585f-5561-9f2f-a6289a1035eb',\n",
       " 'text-embedding-ada-0022f3abaae-2a0b-5798-bbc1-b71487ecb9e8',\n",
       " 'text-embedding-ada-002406003a5-f81c-574a-b887-d92035dd6125',\n",
       " 'text-embedding-ada-00227fd8b76-ba68-5c11-8b58-131c9673ec0c',\n",
       " 'text-embedding-ada-0026836d5d4-629b-5c6b-bc08-56e17603a4e5',\n",
       " 'text-embedding-ada-0021bd398de-c441-558d-8550-394a76af604d',\n",
       " 'text-embedding-ada-002db813d41-dec0-5372-9dff-92eb516f0aee',\n",
       " 'text-embedding-ada-0025b42b701-2c3f-5865-a195-fafa3583af35',\n",
       " 'text-embedding-ada-0027bc0c433-17fb-54e3-b3d6-2fd38dad142b',\n",
       " 'text-embedding-ada-002ac1fda5c-7511-5ab2-819d-309aea243af4',\n",
       " 'text-embedding-ada-002cd9c1ae8-5b38-5910-8670-65729b4316cf',\n",
       " 'text-embedding-ada-00297b12021-0f7d-5868-b8d4-2f417c3a60af',\n",
       " 'text-embedding-ada-002baca9eb7-f70c-5310-9f37-c9f4476dadfd',\n",
       " 'text-embedding-ada-002f32b2328-b2b9-5038-8f07-9932003c3f01',\n",
       " 'text-embedding-ada-002744e5fb4-2d34-5a2e-9e93-34d595884277',\n",
       " 'text-embedding-ada-0021645e19f-e3e2-5020-a7f1-4328a98b47e1',\n",
       " 'text-embedding-ada-002f3fefb2b-65ea-531c-9953-60cfa61c6b5e',\n",
       " 'text-embedding-ada-002bd5b105e-e7dd-59c5-975c-31804d6583e2',\n",
       " 'text-embedding-ada-0024a97f114-17fa-5a84-ad51-530cd14bfbc3',\n",
       " 'text-embedding-ada-002dc6da046-2e14-521d-bdc4-277aad581859',\n",
       " 'text-embedding-ada-00263f5e682-5fdd-5218-8d42-8a1e3470a121',\n",
       " 'text-embedding-ada-0029b68e547-52d6-5364-9ec2-1de26ed633cf',\n",
       " 'text-embedding-ada-0023df861e4-5e29-5a08-9b79-b37fedc78528',\n",
       " 'text-embedding-ada-002e54946a8-f68f-5138-a3a7-5eb7a14798be',\n",
       " 'text-embedding-ada-002c761a907-d8c5-53a3-9df5-f0440a898368',\n",
       " 'text-embedding-ada-00236931354-2ce8-585b-b281-3e780c1d2268',\n",
       " 'text-embedding-ada-00237264890-582a-5ae9-8153-46267d2ccdbc',\n",
       " 'text-embedding-ada-002f4ec1193-cc49-5aad-ae44-f56df9098a0f',\n",
       " 'text-embedding-ada-0022b8b88ac-2bfc-54c8-827a-064661d1c6eb',\n",
       " 'text-embedding-ada-002e87ff996-aa34-5b7c-86fe-23b316436854',\n",
       " 'text-embedding-ada-002fcdfa9df-eced-5a11-b7ae-e6e9c543d3c1',\n",
       " 'text-embedding-ada-002aeb4c7be-0f84-5850-b3c7-8597899fc0e1',\n",
       " 'text-embedding-ada-0029e1f1ae2-61ab-5e04-96b4-079ca4b6b03a',\n",
       " 'text-embedding-ada-002207e5b7e-3b22-5e5a-9a88-a0430b103290',\n",
       " 'text-embedding-ada-0023fd3e20c-8a5b-5b89-83ce-a384fe36a731',\n",
       " 'text-embedding-ada-002fc085d72-f60e-5ad7-85ca-09ba40bf48b6',\n",
       " 'text-embedding-ada-0027f71373c-15f1-5e20-affc-7babb0c417ad',\n",
       " 'text-embedding-ada-00228eb731f-f309-5a8f-97f3-89ec805a111a',\n",
       " 'text-embedding-ada-002dca4c838-a81e-5a49-81c0-bda39f0e7cbc',\n",
       " 'text-embedding-ada-002f26c4891-ae64-5c44-bb1b-aed5a62bd4b4',\n",
       " 'text-embedding-ada-002ac6066fc-9a05-5fdc-a089-eae23c50b88e',\n",
       " 'text-embedding-ada-002405fb687-d5f1-52cc-840c-10dbbb796d45',\n",
       " 'text-embedding-ada-0029c04929a-c9de-50ac-9f47-fef40924b5d2',\n",
       " 'text-embedding-ada-0029252f2c1-6663-578d-9b49-133ca482da17',\n",
       " 'text-embedding-ada-0026d97b225-dd0e-536e-90dd-8b67f21d99d5',\n",
       " 'text-embedding-ada-0023037f876-1e90-502c-94b9-cc8a78718d23',\n",
       " 'text-embedding-ada-0028052b59a-05a3-5490-9eaf-32546736ff36',\n",
       " 'text-embedding-ada-002b1980fd9-b9df-58cb-9bba-72e89b5ea240',\n",
       " 'text-embedding-ada-0027a3e09e3-f599-5cf0-ba29-7d31cfb3e941',\n",
       " 'text-embedding-ada-002149ad106-ba6c-5228-857e-2957844c2d14',\n",
       " 'text-embedding-ada-002c75c86f7-8891-5db4-a7ff-44963404a933',\n",
       " 'text-embedding-ada-0024cad1f50-03ee-5005-a6ae-3ba04d6bea17',\n",
       " 'text-embedding-ada-0027da2d787-a811-5e80-a22b-672292f14d4a',\n",
       " 'text-embedding-ada-002c9ac368d-25c3-5c37-9de5-9c15df8c68ae',\n",
       " 'text-embedding-ada-0027f0736d5-09e1-5597-a92b-23d31633f70a',\n",
       " 'text-embedding-ada-002228c3ce5-f1a8-56e6-8ad0-aa35594bd9e8',\n",
       " 'text-embedding-ada-002b13a6412-f440-59cf-a3e4-4a70425c0caf',\n",
       " 'text-embedding-ada-0025c5a1403-cae6-5d7e-b0b3-94e6e6d157a7',\n",
       " 'text-embedding-ada-002dea4ce61-615f-5491-b16a-225b61ceb8c8',\n",
       " 'text-embedding-ada-002a69e71a9-f76b-513b-ad2c-e541c26ad4e2',\n",
       " 'text-embedding-ada-0027d3a8651-949a-59b4-b58f-8769a0ada62d',\n",
       " 'text-embedding-ada-0025fb7a5ee-5c4c-522b-8989-50d17b1eca7b',\n",
       " 'text-embedding-ada-00242a42fe7-1588-5499-8783-9ee3d1d8d61a',\n",
       " 'text-embedding-ada-0022fec60df-5d1b-5dcc-975f-532aa10be537',\n",
       " 'text-embedding-ada-0022cc57764-8c6a-5bf0-99e6-961a3a3ff5d2',\n",
       " 'text-embedding-ada-0020b4bb044-e0a2-534b-bee4-edd79a099082',\n",
       " 'text-embedding-ada-00203e5c71d-d5b5-5d81-9e5e-5efbbdb5fcc0',\n",
       " 'text-embedding-ada-002b5ab1ad3-cfab-54a3-93f5-96f1b6a5afef',\n",
       " 'text-embedding-ada-00292f6ba77-9031-5faa-a19d-25864b524ff6',\n",
       " 'text-embedding-ada-002d258e3e2-3c2c-59c6-9252-68849a1297c6',\n",
       " 'text-embedding-ada-002e4cf3463-c397-54cc-ab93-cf6d78d2199c',\n",
       " 'text-embedding-ada-0021a41a3c2-6f20-53ee-b18a-5b67e5c9360e',\n",
       " 'text-embedding-ada-002344e9bf1-2874-5ed2-ab5d-ef4f7d98e25d',\n",
       " 'text-embedding-ada-002abe30fb5-e074-54af-93a4-5a04ea776540',\n",
       " 'text-embedding-ada-002cc38d42c-9741-5218-8ef5-fefbb22e08f5',\n",
       " 'text-embedding-ada-002812b86c1-8ebf-5483-95c6-c95cf2b52d12',\n",
       " 'text-embedding-ada-0028d54f3a4-5dde-56a9-b8a4-7569c596816e',\n",
       " 'text-embedding-ada-00208357f77-9067-5ce5-bf9c-23efc8c25891',\n",
       " 'text-embedding-ada-00259b28ef9-7b4a-500b-9215-9501647bd8fc',\n",
       " 'text-embedding-ada-00228867a97-824a-5c1a-bd18-af7bc4847df5',\n",
       " 'text-embedding-ada-002dd3c711a-87fb-54b0-ad65-1fb5e52594df',\n",
       " 'text-embedding-ada-002395c67cf-3f50-503c-9bf3-9133c316b8c8',\n",
       " 'text-embedding-ada-0022237d189-2154-5e1a-a5bc-7efa899bc231',\n",
       " 'text-embedding-ada-002e8f2d2ff-778f-5eff-a1ce-190c2211cd29',\n",
       " 'text-embedding-ada-002e49768b6-864e-598e-a057-1514e3a0197c',\n",
       " 'text-embedding-ada-002d285eae2-97b7-50e1-a9a8-dbb65e987625',\n",
       " 'text-embedding-ada-0029ba46e68-4024-51a0-8020-0d5cfe84705a',\n",
       " 'text-embedding-ada-00285cdf866-b432-5037-8d7f-76aa70e3f91d',\n",
       " 'text-embedding-ada-00288308a5d-b05b-53fb-9468-5b7037d4e8a1',\n",
       " 'text-embedding-ada-0029fd85f7c-c43c-531d-b392-29761e92e12c',\n",
       " 'text-embedding-ada-00213c613b9-9b19-5ee8-96e0-d3b822ce02e6',\n",
       " 'text-embedding-ada-002c5252378-886f-5d2b-a8a6-fcd254343607',\n",
       " 'text-embedding-ada-002d93a7073-e6ef-5574-8730-ac8ccd987267',\n",
       " 'text-embedding-ada-002a910d6a8-a54a-5df7-a0f9-91617768a701',\n",
       " 'text-embedding-ada-002863a9750-e453-58a5-b793-f3fc96c07243',\n",
       " 'text-embedding-ada-002424b6624-a211-5c90-a252-9062fb490650',\n",
       " 'text-embedding-ada-0029f11c1f0-f5e9-523a-ad10-eac102f57599',\n",
       " 'text-embedding-ada-002398d1cd5-6cf4-505e-b906-ce651377decb',\n",
       " 'text-embedding-ada-002091b1b2d-1ce6-5ec4-a028-f933dc809fb6',\n",
       " 'text-embedding-ada-0028a13aef7-3043-5f56-94ae-2e978059e3e1',\n",
       " 'text-embedding-ada-002fa2bd87a-fc5d-50a9-9676-0c2cc130797b',\n",
       " 'text-embedding-ada-002c16d635d-82d0-53ce-b72f-20d14401dce1',\n",
       " 'text-embedding-ada-002f5c2e554-ab84-555a-b539-572abc58f29f',\n",
       " 'text-embedding-ada-002c7c56ab5-4385-5682-812b-efee8e6e8e64',\n",
       " 'text-embedding-ada-00251b58770-7db0-5bd5-a9ae-eb9d0d57252c',\n",
       " 'text-embedding-ada-0021370c9c6-d53a-5277-8a19-03d20e6a3982',\n",
       " 'text-embedding-ada-002e3d80595-3ada-556d-80d2-9c60658dee8e',\n",
       " 'text-embedding-ada-002959b7570-279e-5108-8cd3-af984fc102bf',\n",
       " 'text-embedding-ada-002cef066d0-2552-5225-ae17-f0c1351f47cd',\n",
       " 'text-embedding-ada-0023f6c3a04-9d9f-5a40-8c70-e8b90ec71fc5',\n",
       " 'text-embedding-ada-00261a58d16-8ec1-5d4b-a752-5e836bf970b1',\n",
       " 'text-embedding-ada-002f2ed9db5-c832-58af-9ed8-98c560b20d7a',\n",
       " 'text-embedding-ada-002192dcd45-a894-51f7-9beb-7de41347ae37',\n",
       " 'text-embedding-ada-002c50425cb-a132-5e32-9f5d-e4292cbd289b',\n",
       " 'text-embedding-ada-00271e364e9-3fb7-5eec-811d-94838282e8e5',\n",
       " 'text-embedding-ada-0024bcca810-8a13-5ff9-96fe-ce097f6d231d',\n",
       " 'text-embedding-ada-002e9a45048-51bb-58f0-888c-aae09aeef689',\n",
       " 'text-embedding-ada-002a36075a8-3e06-5676-ae83-0b00ac3230f8',\n",
       " 'text-embedding-ada-002af89a638-18ed-57eb-bcfe-024da3a6a93c',\n",
       " 'text-embedding-ada-002edebd6ea-dbe2-5c9b-a399-4388d4749118',\n",
       " 'text-embedding-ada-002af54a85c-e04c-5aee-aedd-fb803a65fe7b',\n",
       " 'text-embedding-ada-00287fea93d-471a-532d-be76-678467f40157',\n",
       " 'text-embedding-ada-00227f5b227-c6ba-5d3b-9d0d-6b66b89449dd',\n",
       " 'text-embedding-ada-0027ce52a3c-07b0-5814-970b-efacece52aa4',\n",
       " 'text-embedding-ada-002be8f2e9e-46d4-57c7-8211-238616b27a05',\n",
       " 'text-embedding-ada-0021d97900e-98ba-53f0-b7b3-46d63203cfde',\n",
       " 'text-embedding-ada-002e4bb75a7-e6c3-514a-bfcf-633e01b8bb7c',\n",
       " 'text-embedding-ada-002d8e4dd30-33df-5b55-b2af-940b54fb5046',\n",
       " 'text-embedding-ada-002ba8e97c2-dea4-5eea-9294-d7ea0800d8a5',\n",
       " 'text-embedding-ada-002e17f11cd-e63a-50d3-bc6d-cf29343bedac',\n",
       " 'text-embedding-ada-0029377ef74-66df-5211-aafc-846378750ffb',\n",
       " 'text-embedding-ada-002c4f35bd1-31f1-523a-b05e-97acd8603b12',\n",
       " 'text-embedding-ada-0023c5ea95b-91eb-5a38-85e0-147821b9e606',\n",
       " 'text-embedding-ada-002b02c821e-2c53-58ac-96d6-66897b04ad2a',\n",
       " 'text-embedding-ada-002cec0c0f6-418b-5168-91d4-0b43b48f214b',\n",
       " 'text-embedding-ada-00289bdfd66-df6c-52bd-a962-62abb856985d',\n",
       " 'text-embedding-ada-002cdfdaaa6-49ec-588f-9e08-1ec66700abfc',\n",
       " 'text-embedding-ada-002884ca114-07ec-5ad6-8df9-48e08122b3b3',\n",
       " 'text-embedding-ada-0027615bcb2-46bc-5bd9-b50d-c8fb417f8821',\n",
       " 'text-embedding-ada-0024058fd8b-6bab-5978-8852-3da83e1a0643',\n",
       " 'text-embedding-ada-002da4271ac-537f-561e-a71f-5e624e67aedf',\n",
       " 'text-embedding-ada-0020f6ed6a1-ac53-5aa9-bd3c-f10bc7cc1a7c']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_texts(korea, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Can't use statement directly after '%%time'!\n"
     ]
    }
   ],
   "source": [
    "%%time #시간 측정\n",
    "db2 = FAISS.from_texts(korea, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-embedding-ada-002a0146fd6-d992-5270-a7d0-4e0789f91cd1',\n",
       " 'text-embedding-ada-002218bc9da-cee2-586a-bc37-d41780259536',\n",
       " 'text-embedding-ada-002be8d00b4-6909-593c-a802-63ccb0a79efd',\n",
       " 'text-embedding-ada-00254317ce7-ea08-5df2-acc4-7ba7f72aeace',\n",
       " 'text-embedding-ada-00219bae6aa-dc2c-5fa3-9ca5-6905aabf4a78']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(store.yield_keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(api_key=api_key,temperature=0.1)\n",
    "retriever = db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'CacheBackedEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1249ec790>),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x30a56e850>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x30a5c25e0>, temperature=0.1, openai_api_key='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', openai_proxy='')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네, 손흥민이 있습니다.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"손흥민이 있나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('케빈 더브라위너가 대표팀 명단에 있나요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes.'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"황선홍선수는 명단에 있나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'두'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"공격수로 차출된 선수는 누가 있나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs = RunnableParallel(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: get_buffer_string(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | ChatOpenAI(api_key=api_key,temperature=0)\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | ChatOpenAI(api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Based on the context provided, it is impossible to determine where Harrison worked.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did harrison work?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='It is not possible to determine where Harrison worked based on the given context.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"where did he work?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"Who wrote this notebook?\"),\n",
    "            AIMessage(content=\"Harrison\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔗 Multiple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La ciudad de Chicago, Illinois, se encuentra en los Estados Unidos.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what country is the city {city} in? respond in {language}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(api_key=api_key)\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"city\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"person\": \"obama\", \"language\": \"spanish\"})\n",
    "\n",
    "\n",
    "\n",
    "#person 이 먼저 호출이되어서 chain1 을 실행 한 후 chain2를 실행함 지금 로직상은 city 를 인자값이 들어가 있지는 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\n",
    "    \"generate a {attribute} color. Return the name of the color and nothing else:\"\n",
    ")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what is a fruit of color: {color}. Return the name of the fruit and nothing else:\"\n",
    ")\n",
    "prompt3 = ChatPromptTemplate.from_template(\n",
    "    \"what is a country with a flag that has the color: {color}. Return the name of the country and nothing else:\"\n",
    ")\n",
    "prompt4 = ChatPromptTemplate.from_template(\n",
    "    \"What is the color of {fruit} and the flag of {country}?\"\n",
    ")\n",
    "\n",
    "model_parser = model | StrOutputParser()\n",
    "\n",
    "color_generator = (\n",
    "    {\"attribute\": RunnablePassthrough()} | prompt1 | {\"color\": model_parser}\n",
    ")\n",
    "color_to_fruit = prompt2 | model_parser\n",
    "color_to_country = prompt3 | model_parser\n",
    "question_generator = (\n",
    "    color_generator | {\"fruit\": color_to_fruit, \"country\": color_to_country} | prompt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='What is the color of Orange and the flag of Bhutan?')])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generator.invoke(\"warm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Both blueberry and the flag of Finland are blue in color.', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = question_generator.invoke('cooltone')\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying a SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase   # eb 연결\n",
    "db = SQLDatabase.from_uri(\"sqlite:///./Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):  # 테이블의 정보를 가져옴\n",
    "    return db.get_table_info()\n",
    "def run_query(query): # 쿼리를 실행\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(api_key=api_key) \n",
    "\n",
    "sql_response = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | model.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(employee_id) as total_employees \\nFROM employees;'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_response.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query} \n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_response).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda x: db.run(x[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: employees\n[SQL: SELECT COUNT(employee_id) \nFROM employees;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1970\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1971\u001b[0m         )\n\u001b[1;32m   1973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 922\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: employees",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb 셀 49\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m full_chain\u001b[39m.\u001b[39;49minvoke({\u001b[39m\"\u001b[39;49m\u001b[39mquestion\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mHow many employees are there?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:2218\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2217\u001b[0m     \u001b[39mfor\u001b[39;00m i, step \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps):\n\u001b[0;32m-> 2218\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\n\u001b[1;32m   2219\u001b[0m             \u001b[39minput\u001b[39;49m,\n\u001b[1;32m   2220\u001b[0m             \u001b[39m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2221\u001b[0m             patch_config(\n\u001b[1;32m   2222\u001b[0m                 config, callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseq:step:\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2223\u001b[0m             ),\n\u001b[1;32m   2224\u001b[0m         )\n\u001b[1;32m   2225\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[1;32m   2226\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/passthrough.py:453\u001b[0m, in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    436\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mdict\u001b[39m\n\u001b[1;32m    437\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m    440\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[1;32m    441\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmapper\u001b[39m.\u001b[39minvoke(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         ),\n\u001b[1;32m    446\u001b[0m     }\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    449\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    450\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m    451\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    452\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m--> 453\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_with_config(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invoke, \u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    456\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_ainvoke\u001b[39m(\n\u001b[1;32m    457\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    458\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    462\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:1405\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1402\u001b[0m     context\u001b[39m.\u001b[39mrun(var_child_runnable_config\u001b[39m.\u001b[39mset, child_config)\n\u001b[1;32m   1403\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1404\u001b[0m         Output,\n\u001b[0;32m-> 1405\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1406\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1407\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1408\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1409\u001b[0m             config,\n\u001b[1;32m   1410\u001b[0m             run_manager,\n\u001b[1;32m   1411\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1412\u001b[0m         ),\n\u001b[1;32m   1413\u001b[0m     )\n\u001b[1;32m   1414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1415\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/passthrough.py:440\u001b[0m, in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_invoke\u001b[39m(\n\u001b[1;32m    429\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    430\u001b[0m     \u001b[39minput\u001b[39m: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    434\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    435\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    436\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mdict\u001b[39m\n\u001b[1;32m    437\u001b[0m     ), \u001b[39m\"\u001b[39m\u001b[39mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m--> 440\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[1;32m    441\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmapper\u001b[39m.\u001b[39minvoke(\n\u001b[1;32m    442\u001b[0m             \u001b[39minput\u001b[39m,\n\u001b[1;32m    443\u001b[0m             patch_config(config, callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child()),\n\u001b[1;32m    444\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    445\u001b[0m         ),\n\u001b[1;32m    446\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:2855\u001b[0m, in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2846\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_schema\u001b[39m(\n\u001b[1;32m   2847\u001b[0m     \u001b[39mself\u001b[39m, config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Type[BaseModel]:\n\u001b[1;32m   2849\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m   2850\u001b[0m         s\u001b[39m.\u001b[39mget_input_schema(config)\u001b[39m.\u001b[39mschema()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2851\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m   2852\u001b[0m     ):\n\u001b[1;32m   2853\u001b[0m         \u001b[39m# This is correct, but pydantic typings/mypy don't think so.\u001b[39;00m\n\u001b[1;32m   2854\u001b[0m         \u001b[39mreturn\u001b[39;00m create_model(  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m-> 2855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_name(\u001b[39m\"\u001b[39m\u001b[39mInput\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   2856\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\n\u001b[1;32m   2857\u001b[0m                 k: (v\u001b[39m.\u001b[39mannotation, v\u001b[39m.\u001b[39mdefault)\n\u001b[1;32m   2858\u001b[0m                 \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m   2859\u001b[0m                 \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m step\u001b[39m.\u001b[39mget_input_schema(config)\u001b[39m.\u001b[39m__fields__\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   2860\u001b[0m                 \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__root__\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2861\u001b[0m             },\n\u001b[1;32m   2862\u001b[0m         )\n\u001b[1;32m   2864\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_input_schema(config)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:2855\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2846\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_schema\u001b[39m(\n\u001b[1;32m   2847\u001b[0m     \u001b[39mself\u001b[39m, config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2848\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Type[BaseModel]:\n\u001b[1;32m   2849\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m   2850\u001b[0m         s\u001b[39m.\u001b[39mget_input_schema(config)\u001b[39m.\u001b[39mschema()\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2851\u001b[0m         \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m   2852\u001b[0m     ):\n\u001b[1;32m   2853\u001b[0m         \u001b[39m# This is correct, but pydantic typings/mypy don't think so.\u001b[39;00m\n\u001b[1;32m   2854\u001b[0m         \u001b[39mreturn\u001b[39;00m create_model(  \u001b[39m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m-> 2855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_name(\u001b[39m\"\u001b[39m\u001b[39mInput\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   2856\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\n\u001b[1;32m   2857\u001b[0m                 k: (v\u001b[39m.\u001b[39mannotation, v\u001b[39m.\u001b[39mdefault)\n\u001b[1;32m   2858\u001b[0m                 \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m   2859\u001b[0m                 \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m step\u001b[39m.\u001b[39mget_input_schema(config)\u001b[39m.\u001b[39m__fields__\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   2860\u001b[0m                 \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__root__\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2861\u001b[0m             },\n\u001b[1;32m   2862\u001b[0m         )\n\u001b[1;32m   2864\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_input_schema(config)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:3669\u001b[0m, in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3655\u001b[0m         output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39minvoke(\n\u001b[1;32m   3656\u001b[0m             \u001b[39minput\u001b[39m,\n\u001b[1;32m   3657\u001b[0m             patch_config(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3661\u001b[0m             ),\n\u001b[1;32m   3662\u001b[0m         )\n\u001b[1;32m   3663\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(Output, output)\n\u001b[1;32m   3665\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39m_ainvoke\u001b[39m(\n\u001b[1;32m   3666\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   3667\u001b[0m     \u001b[39minput\u001b[39m: Input,\n\u001b[1;32m   3668\u001b[0m     run_manager: AsyncCallbackManagerForChainRun,\n\u001b[0;32m-> 3669\u001b[0m     config: RunnableConfig,\n\u001b[1;32m   3670\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m   3671\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[1;32m   3672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mafunc\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m   3673\u001b[0m         afunc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafunc\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:1405\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     context \u001b[39m=\u001b[39m copy_context()\n\u001b[1;32m   1402\u001b[0m     context\u001b[39m.\u001b[39mrun(var_child_runnable_config\u001b[39m.\u001b[39mset, child_config)\n\u001b[1;32m   1403\u001b[0m     output \u001b[39m=\u001b[39m cast(\n\u001b[1;32m   1404\u001b[0m         Output,\n\u001b[0;32m-> 1405\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m   1406\u001b[0m             call_func_with_variable_args,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1407\u001b[0m             func,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1408\u001b[0m             \u001b[39minput\u001b[39;49m,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1409\u001b[0m             config,\n\u001b[1;32m   1410\u001b[0m             run_manager,\n\u001b[1;32m   1411\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1412\u001b[0m         ),\n\u001b[1;32m   1413\u001b[0m     )\n\u001b[1;32m   1414\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1415\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py:3543\u001b[0m, in \u001b[0;36m_invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3540\u001b[0m try:\n\u001b[1;32m   3541\u001b[0m     sig = inspect.signature(func)\n\u001b[1;32m   3542\u001b[0m     if sig.return_annotation != inspect.Signature.empty:\n\u001b[0;32m-> 3543\u001b[0m         # unwrap iterator types\n\u001b[1;32m   3544\u001b[0m         if getattr(sig.return_annotation, \"__origin__\", None) in (\n\u001b[1;32m   3545\u001b[0m             collections.abc.Iterator,\n\u001b[1;32m   3546\u001b[0m             collections.abc.AsyncIterator,\n\u001b[1;32m   3547\u001b[0m         ):\n\u001b[1;32m   3548\u001b[0m             return getattr(sig.return_annotation, \"__args__\", (Any,))[0]\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/config.py:326\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m run_manager \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    325\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m run_manager\n\u001b[0;32m--> 326\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;32m/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb 셀 49\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m full_chain \u001b[39m=\u001b[39m (\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     RunnablePassthrough\u001b[39m.\u001b[39massign(query\u001b[39m=\u001b[39msql_response)\u001b[39m.\u001b[39massign(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         schema\u001b[39m=\u001b[39mget_schema,\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         response\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: db\u001b[39m.\u001b[39;49mrun(x[\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m|\u001b[39m prompt_response\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m|\u001b[39m model\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y105sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_community/utilities/sql_database.py:498\u001b[0m, in \u001b[0;36mSQLDatabase.run\u001b[0;34m(self, command, fetch, include_columns, parameters, execution_options)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\n\u001b[1;32m    485\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    486\u001b[0m     command: Union[\u001b[39mstr\u001b[39m, Executable],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m     execution_options: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[\u001b[39mstr\u001b[39m, Sequence[Dict[\u001b[39mstr\u001b[39m, Any]], Result[Any]]:\n\u001b[1;32m    493\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Execute a SQL command and return a string representing the results.\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \n\u001b[1;32m    495\u001b[0m \u001b[39m    If the statement returns rows, a string of the results is returned.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[39m    If the statement returns no rows, an empty string is returned.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 498\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(\n\u001b[1;32m    499\u001b[0m         command, fetch, parameters\u001b[39m=\u001b[39;49mparameters, execution_options\u001b[39m=\u001b[39;49mexecution_options\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    502\u001b[0m     \u001b[39mif\u001b[39;00m fetch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcursor\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    503\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_community/utilities/sql_database.py:463\u001b[0m, in \u001b[0;36mSQLDatabase._execute\u001b[0;34m(self, command, fetch, parameters, execution_options)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuery expression has unknown type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(command)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 463\u001b[0m cursor \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    464\u001b[0m     command,\n\u001b[1;32m    465\u001b[0m     parameters,\n\u001b[1;32m    466\u001b[0m     execution_options\u001b[39m=\u001b[39;49mexecution_options,\n\u001b[1;32m    467\u001b[0m )\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m cursor\u001b[39m.\u001b[39mreturns_rows:\n\u001b[1;32m    470\u001b[0m     \u001b[39mif\u001b[39;00m fetch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1416\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1416\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[1;32m   1417\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1418\u001b[0m         distilled_parameters,\n\u001b[1;32m   1419\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[1;32m   1420\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:516\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    515\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    517\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[1;32m    518\u001b[0m     )\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1639\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1627\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1628\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1629\u001b[0m )\n\u001b[1;32m   1631\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1632\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1633\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1637\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1638\u001b[0m )\n\u001b[0;32m-> 1639\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1640\u001b[0m     dialect,\n\u001b[1;32m   1641\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1642\u001b[0m     compiled_sql,\n\u001b[1;32m   1643\u001b[0m     distilled_parameters,\n\u001b[1;32m   1644\u001b[0m     execution_options,\n\u001b[1;32m   1645\u001b[0m     compiled_sql,\n\u001b[1;32m   1646\u001b[0m     distilled_parameters,\n\u001b[1;32m   1647\u001b[0m     elem,\n\u001b[1;32m   1648\u001b[0m     extracted_params,\n\u001b[1;32m   1649\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1650\u001b[0m )\n\u001b[1;32m   1651\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1653\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1654\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1658\u001b[0m         ret,\n\u001b[1;32m   1659\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1848\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1843\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1844\u001b[0m         dialect,\n\u001b[1;32m   1845\u001b[0m         context,\n\u001b[1;32m   1846\u001b[0m     )\n\u001b[1;32m   1847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1848\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1849\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1850\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1988\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1985\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1987\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1988\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1989\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[1;32m   1992\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2343\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2342\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2343\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2345\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1969\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1968\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1969\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1970\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1971\u001b[0m         )\n\u001b[1;32m   1973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1975\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1976\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1980\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1981\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/sqlalchemy/engine/default.py:922\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 922\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: employees\n[SQL: SELECT COUNT(employee_id) \nFROM employees;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": \"How many employees are there?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, tool\n",
    "from langchain.agents.output_parsers import XMLAgentOutputParser\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "claude_api_key = 'your_api_key'\n",
    "model = ChatAnthropic(model=\"claude-2\",anthropic_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search things about current events.\"\"\"\n",
    "    return \"32 degrees\"\n",
    "\n",
    "tool_list = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"hwchase17/xml-agent-convo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input', 'tools'] partial_variables={'chat_history': ''} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input', 'tools'], template=\"You are a helpful assistant. Help the user answer any questions.\\n\\nYou have access to the following tools:\\n\\n{tools}\\n\\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\\n\\n<tool>search</tool><tool_input>weather in SF</tool_input>\\n<observation>64 degrees</observation>\\n\\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\\n\\n<final_answer>The weather in SF is 64 degrees</final_answer>\\n\\nBegin!\\n\\nPrevious Conversation:\\n{chat_history}\\n\\nQuestion: {input}\\n{agent_scratchpad}\"))]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic for going from intermediate steps to a string to pass into model\n",
    "# This is pretty tied to the prompt\n",
    "def convert_intermediate_steps(intermediate_steps):\n",
    "    log = \"\"\n",
    "    for action, observation in intermediate_steps:\n",
    "        log += (\n",
    "            f\"<tool>{action.tool}</tool><tool_input>{action.tool_input}\"\n",
    "            f\"</tool_input><observation>{observation}</observation>\"\n",
    "        )\n",
    "    return log\n",
    "\n",
    "\n",
    "# Logic for converting tools to string to go in prompt\n",
    "def convert_tools(tools):\n",
    "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: convert_intermediate_steps(\n",
    "            x[\"intermediate_steps\"]\n",
    "        ),\n",
    "    }\n",
    "    | prompt.partial(tools=convert_tools(tool_list))\n",
    "    | model.bind(stop=[\"</tool_input>\", \"</final_answer>\"])\n",
    "    | XMLAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tool_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m <tool>search</tool><tool_input>오타니의 최근성적\u001b[0m\u001b[36;1m\u001b[1;3m32 degrees\u001b[0m\u001b[32;1m\u001b[1;3m <tool>search</tool><tool_input>오타니의 최근성적\u001b[0m\u001b[36;1m\u001b[1;3m32 degrees\u001b[0m\u001b[32;1m\u001b[1;3m <tool>search</tool><tool_input>오타니의 최근성적\u001b[0m\u001b[36;1m\u001b[1;3m32 degrees\u001b[0m\u001b[32;1m\u001b[1;3m <tool>search</tool><tool_input>오타니의 최근성적\u001b[0m\u001b[36;1m\u001b[1;3m32 degrees\u001b[0m\u001b[32;1m\u001b[1;3m <tool>search</tool><tool_input>오타니의 최근 성적\u001b[0m\u001b[36;1m\u001b[1;3m32 degrees\u001b[0mUnexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d4/56xjd1v51xq5ybs0jdmq217h0000gn/T/ipykernel_45393/3644363406.py\", line 1, in <module>\n",
      "    agent_executor.invoke({\"input\": \"오타니의 최근성적은 어때?\"})\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/chains/base.py\", line 163, in invoke\n",
      "    raise e\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/chains/base.py\", line 153, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1432, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1138, in _take_next_step\n",
      "    [\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1138, in <listcomp>\n",
      "    [\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1166, in _iter_next_step\n",
      "    output = self.agent.plan(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 397, in plan\n",
      "    for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 2589, in stream\n",
      "    )\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 2576, in transform\n",
      "    else:\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 1656, in _transform_stream_with_config\n",
      "    for callback_manager, input, config in zip(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 2540, in _transform\n",
      "    remaining_idxs = [\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 1180, in transform\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 4430, in transform\n",
      "    inputs,\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 1197, in transform\n",
      "    input: Iterator[Input],\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 258, in stream\n",
      "    await self.ainvoke(input, config=config, stop=stop, **kwargs),\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 241, in stream\n",
      "    run_manager.on_llm_end(LLMResult(generations=[[generation]]))\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_community/chat_models/anthropic.py\", line 148, in _stream\n",
      "    stream_resp = self.client.completions.create(**params, stream=True)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/resources/completions.py\", line 385, in create\n",
      "    return self._post(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 1208, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 897, in request\n",
      "    return self._request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 973, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 1021, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 973, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 1021, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 988, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.RateLimitError: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of requests has exceeded your rate limit (https://docs.anthropic.com/claude/reference/rate-limits). Please try again later or contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"오타니의 최근성적은 어때?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d4/56xjd1v51xq5ybs0jdmq217h0000gn/T/ipykernel_45393/3694676024.py\", line 1, in <module>\n",
      "    agent_executor.invoke({\"input\": \"whats the weather in New york?\"})\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/chains/base.py\", line 163, in invoke\n",
      "    raise e\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/chains/base.py\", line 153, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1432, in _call\n",
      "    next_step_output = self._take_next_step(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1138, in _take_next_step\n",
      "    [\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1138, in <listcomp>\n",
      "    [\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 1166, in _iter_next_step\n",
      "    output = self.agent.plan(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain/agents/agent.py\", line 397, in plan\n",
      "    for chunk in self.runnable.stream(inputs, config={\"callbacks\": callbacks}):\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 2589, in stream\n",
      "    )\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 2576, in transform\n",
      "    else:\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 1656, in _transform_stream_with_config\n",
      "    for callback_manager, input, config in zip(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 2540, in _transform\n",
      "    remaining_idxs = [\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 1180, in transform\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 4430, in transform\n",
      "    inputs,\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/runnables/base.py\", line 1197, in transform\n",
      "    input: Iterator[Input],\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 258, in stream\n",
      "    await self.ainvoke(input, config=config, stop=stop, **kwargs),\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\", line 241, in stream\n",
      "    run_manager.on_llm_end(LLMResult(generations=[[generation]]))\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_community/chat_models/anthropic.py\", line 148, in _stream\n",
      "    stream_resp = self.client.completions.create(**params, stream=True)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/resources/completions.py\", line 385, in create\n",
      "    return self._post(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 1208, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 897, in request\n",
      "    return self._request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 973, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 1021, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 973, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 1021, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/anthropic/_base_client.py\", line 988, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "anthropic.RateLimitError: Error code: 429 - {'type': 'error', 'error': {'type': 'rate_limit_error', 'message': 'Number of requests has exceeded your rate limit (https://docs.anthropic.com/claude/reference/rate-limits). Please try again later or contact sales at https://www.anthropic.com/contact-sales to discuss your options for a rate limit increase.'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2142, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/kdb/anaconda3/envs/kdb/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in New york?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "#프롬프트 엔지니어링이다.\n",
    "template = \"\"\"Write some python code to solve the user's problem. \n",
    "\n",
    "Return only python code in Markdown format, e.g.:\n",
    "\n",
    "```python\n",
    "....\n",
    "```\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])\n",
    "\n",
    "model = ChatOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_output(text: str):\n",
    "    _, after = text.split(\"```python\") # ```python을 기준으로 나눔\n",
    "    return after.split(\"```\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | StrOutputParser() | _sanitize_output | PythonREPL().run #python 코드를 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"whats 2 multiplied by 3?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing by semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_api_key = 'your_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "#물리학 전문가 템플릿\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\ \n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "#수학 전문가 템플릿\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key = \"your_openai_api_key\")\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"]) #쿼리를 받아서 임베딩을 한다.\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0] # 코사인 유사도를 쿼리에 대한 임베딩과 템플릿 임베딩을 비교한다.\n",
    "    most_similar = prompt_templates[similarity.argmax()] #가장 유사한 템플릿을 선택한다.\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\") #수학이나 물리학 템플릿을 사용한다.\n",
    "    return PromptTemplate.from_template(most_similar) #가장 유사한 템플릿을 반환한다.\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI(api_key=op_api_key)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "The first person to land on the moon was Neil Armstrong on July 20, 1969 as part of the Apollo 11 mission.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"최초로 달에 착륙한사람\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MATH\n",
      "A partial differential equation is an equation that involves partial derivatives of an unknown function of several independent variables. These types of equations are commonly used to model physical phenomena in areas such as physics, engineering, and economics. The solution to a partial differential equation is a function that satisfies the equation and its boundary or initial conditions.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What is a partial differential?\")) #편미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(api_key = op_api_key)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True) #대화형 메모리\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요, 김덕배님! 케빈 더 브라우너를 좋아하는군요. 그의 영화나 음악 등 무엇을 좋아하시나요? 어떤 도움이 필요하신가요?', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"내이름은 김덕배야 안녕. 나는 케빈더브라위너를 좋아해\"}\n",
    "response = chain.invoke(inputs)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(inputs, {\"output\": response.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='hi im bob'),\n",
       "  AIMessage(content='Hello Bob! How can I assist you today?'),\n",
       "  HumanMessage(content='내이름은 김덕배야 안녕. 나는 케빈더브라위너를 좋아해'),\n",
       "  AIMessage(content='안녕하세요, 김덕배님! 케빈 더 브라우너를 좋아하는군요. 그의 영화나 음악 등 무엇을 좋아하시나요? 어떤 도움이 필요하신가요?')]}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='죄송합니다, 혼란을 드려 죄송합니다. 앞서 말씀하신 대로 케빈 더 브라우너를 좋아하신다고 했습니다. 다른 질문이 있으시면 언제든지 물어보세요!', response_metadata={'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"input\": \"내가 누구를 좋아한다고?\"}\n",
    "response = chain.invoke(inputs) #bob이란걸 알고 대답한다.\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIModerationChain\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb 셀 77\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y146sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprompts\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatPromptTemplate\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y146sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_openai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAI\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kdb/Desktop/RAG_examples/Cookbooks.ipynb#Y146sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m moderate \u001b[39m=\u001b[39m OpenAIModerationChain(api_key\u001b[39m=\u001b[39;49mop_api_key)\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/langchain_core/load/serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/kdb/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[39m'\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIModerationChain\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import OpenAIModerationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "moderate = OpenAIModerationChain(api_key=op_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gpt-researcher 0.0.8 requires duckduckgo-search==3.9.8, but you have duckduckgo-search 5.1.0 which is incompatible.\n",
      "gpt-researcher 0.0.8 requires langchain==0.0.335, but you have langchain 0.1.13 which is incompatible.\n",
      "gpt-researcher 0.0.8 requires openai~=1.3.3, but you have openai 1.12.0 which is incompatible.\n",
      "gpt-researcher 0.0.8 requires tavily-python==0.2.8, but you have tavily-python 0.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-openai duckduckgo-search\n",
    "# duckduckgo-search 검색엔진이다.\n",
    "# 활용할 수 있는게 많음\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "template = \"\"\"turn the following user input into a search query for a search engine:\n",
    "\n",
    "{input}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = ChatOpenAI(api_key=op_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | StrOutputParser() | search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"관련글. 오늘은 지난 주말에 열렸던 잉글랜드 프리미어리그 25라운드 결과 및 팀 순위와 돌아오는 주말에 치러지는 26라운드 일정을 알아보도록 하겠습니다. 프리미어리그 25라운드 결과 브렌트포드 1 - 4 리버풀 번리 0 - 5 아스날 풀럼 1 - 2 아스톤빌라 뉴캐슬 2 - 2 ... 정식 명칭은 'Premier League' 입니다. 하지만 편의상 'EPL' 을 쓴다고 하네요. 총 20개팀이 리그를 치루게 됩니다. 프리미어리그(EPL)는 1992년 2월에 창설되어. 올해 31주년을 맞이한 리그 라고 볼 수 있습니다. 최다 우승팀은 맨유로 총 20회 우승 을 했고, 1. 2021-2022 English Premier League(EPL) 시즌 개요 2021-2022 English Premier League(EPL) 시즌은 매년 열리는 잉글랜드 프로페셔널 리그 1부 리그인 EPL의 새로운 시즌을 맞이하는 것이다. 이 시즌에는 잉글랜드의 각 지역에서 온 20개의 클럽이 참가하여 총 380경기가 펼쳐질 예정이다. 이번주 토트넘 경기일정 토트넘은 17일 오전 2시 30분 EPL 29라운드 원정경기에서 풀럼FC와 격돌하는데요. 최근 기세가 매서운 캡틴 손흥민선수가 국가대표팀 소집을 앞두고 3경기 연속골을 정조준합니다. 아시아인 최초 한 경기 4 ... epl은 한국팬들에겐 가장 인기 있는 유럽 리그 중 하나인데, ... 손흥민이 2016-17 시즌 14골, 2020-21 시즌 17골, 2021-22 시즌 23골을 기록하며 재차 경신했다. 이는 아시아인 최초의 두 자리수 득점이며 한국인임을 떠나 아시아인으로서도 큰 ...\""
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"이번주에 EPL 경기일정을 알고싶어!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
